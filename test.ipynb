{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinta_redshift\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import time\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "import uuid\n",
    "from pandas import DataFrame\n",
    "\n",
    "def table_to_dataframe(table, schema, database='landing_zone', NUM_ENTRIES=0, cluster_identifier='redshift-data', region_name='us-west-2', db_user='admintreinta'):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL en Amazon Redshift para extraer datos de una tabla específica y devuelve los resultados como un DataFrame de pandas.\n",
    "    \n",
    "    Parámetros:\n",
    "    - table : Nombre de la tabla a consultar.\n",
    "    - schema: Esquema de la base de datos donde se encuentra la tabla.\n",
    "    - database: Nombre de la base de datos donde se encuentra la tabla.\n",
    "    - NUM_ENTRIES: Número máximo de entradas a retornar. Si es 0, retorna todas las entradas.\n",
    "    - cluster_identifier: Identificador del clúster de Amazon Redshift.\n",
    "    - db_user: Usuario de la base de datos para ejecutar la consulta.\n",
    "    \n",
    "    Retorna:\n",
    "    - Un DataFrame de pandas con los resultados de la consulta.\n",
    "    \"\"\"\n",
    "    client = boto3.client('redshift-data', region_name=region_name)\n",
    "    sql_query = f\"SELECT * FROM {schema}.{table} \"\n",
    "    if NUM_ENTRIES > 0:\n",
    "        sql_query += f\"LIMIT {NUM_ENTRIES}\"\n",
    "        \n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "\n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera hasta que la consulta se haya completado\n",
    "    status = ''\n",
    "    while status not in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de verificar el estado nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Current status: {status}\")\n",
    "    \n",
    "    if status == 'FINISHED':\n",
    "        response = client.get_statement_result(Id=statement_id)\n",
    "        \n",
    "        # Extrayendo los nombres de las columnas de la metadata de columnas\n",
    "        column_metadata = response['ColumnMetadata']\n",
    "        column_names = [column['name'] for column in column_metadata]\n",
    "        \n",
    "        # Construyendo el DataFrame\n",
    "        records = response['Records']\n",
    "        df_rows = []\n",
    "        for record in records:\n",
    "            row = []\n",
    "            for field in record:\n",
    "                if 'isNull' in field and field['isNull']:\n",
    "                    row.append(None)\n",
    "                elif 'stringValue' in field:\n",
    "                    row.append(field['stringValue'])\n",
    "                elif 'longValue' in field:\n",
    "                    row.append(field['longValue'])\n",
    "                elif 'doubleValue' in field:\n",
    "                    row.append(field['doubleValue'])\n",
    "                else:\n",
    "                    row.append(None)  # Añadir soporte para más tipos según sea necesario\n",
    "            df_rows.append(row)\n",
    "        \n",
    "        df = DataFrame(df_rows, columns=column_names)\n",
    "        \n",
    "        return df\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(f\"Error: {error_message}\")\n",
    "        return DataFrame()  # Retorna un DataFrame vacío si la consulta falla\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "        return DataFrame()  # Retorna un DataFrame vacío si la consulta falla\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def query_to_dataframe(sql_query, cluster_identifier='redshift-data', database=\"landing_zone\", region_name='us-west-2', db_user='admintreinta'):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL en Amazon Redshift y devuelve los resultados como un DataFrame de pandas.\n",
    "    \n",
    "    Parámetros:\n",
    "    - sql_query: Consulta SQL para ejecutar.\n",
    "    - cluster_identifier: Identificador del cluster de Amazon Redshift.\n",
    "    - database: Nombre de la base de datos.\n",
    "    - db_user: Usuario de la base de datos.\n",
    "    \n",
    "    Retorna:\n",
    "    - Un DataFrame de pandas con los resultados de la consulta.\n",
    "    \"\"\"\n",
    "    client = boto3.client('redshift-data', region_name=region_name)\n",
    "    \n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "\n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera hasta que la consulta se haya completado\n",
    "    status = ''\n",
    "    while status not in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de verificar el estado nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Current status: {status}\")\n",
    "    \n",
    "    if status == 'FINISHED':\n",
    "        response1 = client.get_statement_result(Id=statement_id)\n",
    "        \n",
    "        # Extrayendo los nombres de las columnas de la metadata de columnas\n",
    "        column_metadata = response1['ColumnMetadata']\n",
    "        column_names = [column['name'] for column in column_metadata]\n",
    "        \n",
    "        # Construyendo el DataFrame\n",
    "        df = DataFrame([[\n",
    "            field.get('stringValue') if 'stringValue' in field else\n",
    "            field.get('longValue') if 'longValue' in field else\n",
    "            field.get('doubleValue') if 'doubleValue' in field else\n",
    "            None for field in record] for record in response1['Records']],\n",
    "            columns=column_names)\n",
    "        \n",
    "        return df\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(f\"Error: {error_message}\")\n",
    "        return DataFrame()  # Retorna un DataFrame vacío si la consulta falla\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "        return DataFrame()  # Retorna un DataFrame vacío si la consulta falla\n",
    "\n",
    "\n",
    "def dataframe_to_s3(df, bucket=\"redshift-python-datalake\", endpoint='data_lake', region_name='us-west-2', object_name=''):\n",
    "    # Generar un sello de tiempo con el formato deseado\n",
    "    timestamp = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S_%f')\n",
    "    year = datetime.datetime.now().strftime('%Y')\n",
    "    month = datetime.datetime.now().strftime('%m')\n",
    "    day = datetime.datetime.now().strftime('%d')\n",
    "    # Generar un identificador único (puedes reemplazarlo por cualquier otra cadena aleatoria si prefieres)\n",
    "    if object_name == '':\n",
    "        object_name = uuid.uuid4().hex\n",
    "        \n",
    "    object_path = f\"{endpoint}/{year}/{month}/{day}/{object_name}_{timestamp}.csv.gz\"\n",
    "\n",
    "    # Usar BytesIO para datos binarios\n",
    "    csv_buffer = BytesIO()\n",
    "    df.to_csv(csv_buffer, index=False, compression='gzip')\n",
    "    \n",
    "    # Es necesario mover el puntero del buffer al inicio después de escribir en él\n",
    "    csv_buffer.seek(0)\n",
    "\n",
    "    s3_resource = boto3.resource('s3', region_name=region_name)\n",
    "    s3_resource.Object(bucket, object_path).put(Body=csv_buffer.getvalue())\n",
    "    \n",
    "    return f's3://{bucket}/{object_path}'\n",
    "\n",
    "def load_s3_to_redshift(table,schema, s3_object_path, database='landing_zone', cluster_identifier='redshift-data', db_user='admintreinta', region_name='us-west-2'):\n",
    "    client = boto3.client('redshift-data')\n",
    "    sql = f\"\"\"\n",
    "        COPY {database}.{schema}.{table}\n",
    "        FROM '{s3_object_path}'\n",
    "        IAM_ROLE default\n",
    "        delimiter ','\n",
    "        IGNOREHEADER 1\n",
    "        GZIP\n",
    "        CSV;\n",
    "    \"\"\"\n",
    "\n",
    "    print(sql)\n",
    "    # Ejecuta el comando COPY\n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql\n",
    "    )\n",
    "    \n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera a que la ejecución termine\n",
    "    status = 'STARTED'\n",
    "    while status in ['SUBMITTED', 'STARTED', 'PICKED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de consultar nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Estado actual: {status}\")\n",
    "\n",
    "    # Verifica el resultado de la ejecución\n",
    "    if status == 'FINISHED':\n",
    "        print(\"La carga ha sido exitosa.\")\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(f\"Error al truncar la tabla: {error_message}\")\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "    \n",
    "        \n",
    "    return response\n",
    "\n",
    "def execute_SP(store_procedure,schema,database = \"landing_zone\", cluster_identifier = 'redshift-data', db_user = 'admintreinta', region_name='us-west-2'):\n",
    "    \"\"\"\n",
    "    Ejecuta una un store en Amazon Redshift\n",
    "    \n",
    "    Parámetros:\n",
    "    - store_procedure: nombre del store procedure a ejecutar\n",
    "    - schema: Esquema en el que se encuentra el store procedure.\n",
    "    - database: Nombre de la base de datos.\n",
    "    - cluster_identifier: Identificador del cluster de Amazon Redshift.\n",
    "    - db_user: Usuario de la base de datos.\n",
    "    \n",
    "    \n",
    "    Retorna:\n",
    "    - Un DataFrame de pandas con los resultados de la consulta.\n",
    "    \"\"\"\n",
    "    client = boto3.client('redshift-data', region_name=region_name)\n",
    "    \n",
    "    sql_query = f\"CALL {database}.{schema}.{store_procedure}()\"\n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "\n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera hasta que la consulta se haya completado\n",
    "    status = ''\n",
    "    while status not in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de verificar el estado nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Current status: {status}\")\n",
    "    if status == 'FINISHED':\n",
    "        print ('Store Procedure ejecutado')\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(error_message)\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "        return 0\n",
    "\n",
    "def truncate_table(table, schema, database = \"landing_zone\", cluster_identifier = 'redshift-data', db_user = 'admintreinta', region_name='us-west-2'):\n",
    "    \"\"\"\n",
    "    Ejecuta una un store en Amazon Redshift\n",
    "    \n",
    "    Parámetros:\n",
    "    - table: tabla a truncar\n",
    "    - schema: Esquema en el que se encuentra el store procedure.\n",
    "    - store_procedure: nombre del store procedure a ejecutar\n",
    "    - cluster_identifier: Identificador del cluster de Amazon Redshift.\n",
    "    - database: Nombre de la base de datos.\n",
    "    - db_user: Usuario de la base de datos.\n",
    "    \n",
    "    \n",
    "    Retorna:\n",
    "    - Un DataFrame de pandas con los resultados de la consulta.\n",
    "    \"\"\"\n",
    "    client = boto3.client('redshift-data', region_name=region_name)\n",
    "    \n",
    "    sql_query = f\"TRUNCATE {database}.{schema}.{table}\"\n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "\n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera hasta que la consulta se haya completado\n",
    "    status = ''\n",
    "    while status not in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de verificar el estado nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Current status: {status}\")\n",
    "    \n",
    "    if status == 'FINISHED':\n",
    "        print ('Store Procedure ejecutado')\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(f\"Error al truncar la tabla: {error_message}\")\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "    return 0\n",
    "\n",
    "def drop_table(table, schema, database = \"landing_zone\", cluster_identifier = 'redshift-data', db_user = 'admintreinta', region_name='us-west-2'):\n",
    "    \"\"\"\n",
    "    Ejecuta una un store en Amazon Redshift\n",
    "    \n",
    "    Parámetros:\n",
    "    - table: tabla a truncar\n",
    "    - schema: Esquema en el que se encuentra el store procedure.\n",
    "    - database: Nombre de la base de datos.\n",
    "    - store_procedure: nombre del store procedure a ejecutar\n",
    "    - cluster_identifier: Identificador del cluster de Amazon Redshift.\n",
    "    \n",
    "    - db_user: Usuario de la base de datos.\n",
    "    \n",
    "    \n",
    "    Retorna:\n",
    "    - Un DataFrame de pandas con los resultados de la consulta.\n",
    "    \"\"\"\n",
    "    client = boto3.client('redshift-data', region_name=region_name)\n",
    "    \n",
    "    sql_query = f\"DROP TABLE {database}.{schema}.{table}\"\n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "\n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera hasta que la consulta se haya completado\n",
    "    status = ''\n",
    "    while status not in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de verificar el estado nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Current status: {status}\")\n",
    "    \n",
    "    if status == 'FINISHED':\n",
    "        print ('Taabla eliminada!')\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(f\"Error al eliminar la tabla: {error_message}\")\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "        return 0\n",
    "\n",
    "def sql_query(sql_query, database = \"landing_zone\",cluster_identifier = 'redshift-data', db_user = 'admintreinta', region_name='us-west-2'):\n",
    "    \"\"\"\n",
    "    Ejecuta una un store en Amazon Redshift\n",
    "    \n",
    "    Parámetros:\n",
    "    - sql_query: query a ejecutar en SQL\n",
    "    - database: Nombre de la base de datos.\n",
    "    - cluster_identifier: Identificador del cluster de Amazon Redshift.\n",
    "    - db_user: Usuario de la base de datos.\n",
    "    \n",
    "    \n",
    "    Retorna:\n",
    "    - Un DataFrame de pandas con los resultados de la consulta.\n",
    "    \"\"\"\n",
    "    client = boto3.client('redshift-data', region_name=region_name)\n",
    "    \n",
    "    response = client.execute_statement(\n",
    "        ClusterIdentifier=cluster_identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        Sql=sql_query\n",
    "    )\n",
    "\n",
    "    statement_id = response['Id']\n",
    "    \n",
    "    # Espera hasta que la consulta se haya completado\n",
    "    status = ''\n",
    "    while status not in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "        time.sleep(5)  # Espera 5 segundos antes de verificar el estado nuevamente\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "        print(f\"Current status: {status}\")\n",
    "    \n",
    "    if status == 'FINISHED':\n",
    "        print ('Query ejecutada!')\n",
    "    elif status == 'FAILED':\n",
    "        # Obtiene y muestra el mensaje de error\n",
    "        error_message = status_response.get('Error', 'No se proporcionó información de error.')\n",
    "        print(f\"Error ejecutando la query SQL: {error_message}\")\n",
    "    else:\n",
    "        print(\"La operación fue abortada o no se completó exitosamente.\")\n",
    "\n",
    "        return 0\n",
    "\n",
    "def dataframe_to_redshift(df,table,schema,bucket = \"redshift-python-datalake\" ,database='landing_zone', region='us-west-2',endpoint = 'data_lake',object_name = False,db_user ='admintreinta', cluster_identifier = 'redshift-data'):\n",
    "    s3_object_path = dataframe_to_s3(df, bucket, endpoint, object_name, region_name=region)\n",
    "    output = load_s3_to_redshift(table,schema, s3_object_path, database, cluster_identifier, db_user, region_name=region)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_to_redshift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: FINISHED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>months_frequency</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id months_frequency discount\n",
       "0   1                1        0\n",
       "1   3               12      0.4\n",
       "2   2                6     0.25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_1 = query_to_dataframe(\"SELECT * FROM landing_zone.public.frequency;\", cluster_identifier = 'redshift-data', database = \"landing_zone\", db_user = 'admintreinta')\n",
    "DATA_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataframe_to_s3() got multiple values for argument 'region_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataframe_to_redshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlanding_zone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 395\u001b[0m, in \u001b[0;36mdataframe_to_redshift\u001b[0;34m(df, table, schema, bucket, database, region_name, endpoint, object_name, db_user, cluster_identifier)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataframe_to_redshift\u001b[39m(df,table,schema,bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredshift-python-datalake\u001b[39m\u001b[38;5;124m\"\u001b[39m ,database\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanding_zone\u001b[39m\u001b[38;5;124m'\u001b[39m, region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-west-2\u001b[39m\u001b[38;5;124m'\u001b[39m,endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_lake\u001b[39m\u001b[38;5;124m'\u001b[39m,object_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,db_user \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmintreinta\u001b[39m\u001b[38;5;124m'\u001b[39m, cluster_identifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredshift-data\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 395\u001b[0m     s3_object_path \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_to_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     output \u001b[38;5;241m=\u001b[39m load_s3_to_redshift(table,schema, s3_object_path, database, cluster_identifier, db_user, region_name\u001b[38;5;241m=\u001b[39mregion_name)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mTypeError\u001b[0m: dataframe_to_s3() got multiple values for argument 'region_name'"
     ]
    }
   ],
   "source": [
    "dataframe_to_redshift(DATA_1,'landing_zone','public')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
